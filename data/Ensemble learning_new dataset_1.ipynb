{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold,  GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import pydotplus  # pip install pydotplus\n",
    "#from sklearn.tree import export_graphviz, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "#from tensorflow.python.keras.layers import LSTM, RepeatVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "# Import pyswarms module\n",
    "import pyswarms as ps\n",
    "from pyswarms.utils.functions import single_obj as fx\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, BatchNormalization, Input, Flatten, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalAveragePooling2D, BatchNormalization, Activation, Add, GaussianNoise, RandomRotation, AveragePooling1D, ReLU, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pydot\n",
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Height</th>\n",
       "      <th>HourS</th>\n",
       "      <th>HourC</th>\n",
       "      <th>CHIS</th>\n",
       "      <th>CHIC</th>\n",
       "      <th>DHS</th>\n",
       "      <th>DHC</th>\n",
       "      <th>F10.7</th>\n",
       "      <th>...</th>\n",
       "      <th>Delta_Kp</th>\n",
       "      <th>DS</th>\n",
       "      <th>DC</th>\n",
       "      <th>IS</th>\n",
       "      <th>LATS</th>\n",
       "      <th>LATC</th>\n",
       "      <th>LONS</th>\n",
       "      <th>LONC</th>\n",
       "      <th>R_Delta_H</th>\n",
       "      <th>foF2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.147514</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.147514</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.147514</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.147514</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.147514</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340659</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340660</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340661</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340662</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340663</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.011587</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>2.941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340664 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date  Hour  Height         HourS  HourC      CHIS      CHIC  \\\n",
       "0         2009-1-1  20.0   150.0 -8.660254e-01    0.5  0.041416  0.999142   \n",
       "1         2009-1-1  20.0   200.0 -8.660254e-01    0.5  0.041416  0.999142   \n",
       "2         2009-1-1  20.0   250.0 -8.660254e-01    0.5  0.041416  0.999142   \n",
       "3         2009-1-1  20.0   300.0 -8.660254e-01    0.5  0.041416  0.999142   \n",
       "4         2009-1-1  20.0   350.0 -8.660254e-01    0.5  0.041416  0.999142   \n",
       "...            ...   ...     ...           ...    ...       ...       ...   \n",
       "340659  2009-12-31  24.0  1800.0 -2.449294e-16    1.0  0.035998  0.999352   \n",
       "340660  2009-12-31  24.0  1850.0 -2.449294e-16    1.0  0.035998  0.999352   \n",
       "340661  2009-12-31  24.0  1900.0 -2.449294e-16    1.0  0.035998  0.999352   \n",
       "340662  2009-12-31  24.0  1950.0 -2.449294e-16    1.0  0.035998  0.999352   \n",
       "340663  2009-12-31  24.0  2000.0 -2.449294e-16    1.0  0.035998  0.999352   \n",
       "\n",
       "             DHS       DHC  F10.7  ...  Delta_Kp        DS       DC        IS  \\\n",
       "0       0.017452  0.999848   10.7  ...  0.104350 -0.004374  0.99999 -0.015666   \n",
       "1       0.017452  0.999848   10.7  ...  0.104350 -0.004374  0.99999 -0.015666   \n",
       "2       0.017452  0.999848   10.7  ...  0.104350 -0.004374  0.99999 -0.015666   \n",
       "3       0.017452  0.999848   10.7  ...  0.104350 -0.004374  0.99999 -0.015666   \n",
       "4       0.017452  0.999848   10.7  ...  0.104350 -0.004374  0.99999 -0.015666   \n",
       "...          ...       ...    ...  ...       ...       ...      ...       ...   \n",
       "340659  0.087156  0.996195   10.7  ...  0.007127 -0.004374  0.99999 -0.015657   \n",
       "340660  0.087156  0.996195   10.7  ...  0.007127 -0.004374  0.99999 -0.015657   \n",
       "340661  0.087156  0.996195   10.7  ...  0.007127 -0.004374  0.99999 -0.015657   \n",
       "340662  0.087156  0.996195   10.7  ...  0.007127 -0.004374  0.99999 -0.015657   \n",
       "340663  0.087156  0.996195   10.7  ...  0.007127 -0.004374  0.99999 -0.015657   \n",
       "\n",
       "            LATS      LATC      LONS      LONC  R_Delta_H   foF2  \n",
       "0      -0.011587  0.999933  0.014377  0.999897  -0.147514  4.325  \n",
       "1      -0.011587  0.999933  0.014377  0.999897  -0.147514  4.325  \n",
       "2      -0.011587  0.999933  0.014377  0.999897  -0.147514  4.325  \n",
       "3      -0.011587  0.999933  0.014377  0.999897  -0.147514  4.325  \n",
       "4      -0.011587  0.999933  0.014377  0.999897  -0.147514  4.325  \n",
       "...          ...       ...       ...       ...        ...    ...  \n",
       "340659 -0.011587  0.999933  0.014377  0.999897  -0.160830  2.941  \n",
       "340660 -0.011587  0.999933  0.014377  0.999897  -0.160830  2.941  \n",
       "340661 -0.011587  0.999933  0.014377  0.999897  -0.160830  2.941  \n",
       "340662 -0.011587  0.999933  0.014377  0.999897  -0.160830  2.941  \n",
       "340663 -0.011587  0.999933  0.014377  0.999897  -0.160830  2.941  \n",
       "\n",
       "[340664 rows x 22 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each station \n",
    "df = pd.read_csv('POMIO2009_foF2.txt', sep =',', skiprows = 1)\n",
    "df.columns = ['Date', 'Hour', 'Height', 'HourS', 'HourC', 'CHIS', 'CHIC', 'DHS', 'DHC', 'F10.7', 'DST_t', 'AP_x', 'Delta_Kp', 'DS', 'DC', 'IS', 'LATS', 'LATC', 'LONS', 'LONC', 'R_Delta_H', 'foF2']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Height</th>\n",
       "      <th>HourS</th>\n",
       "      <th>HourC</th>\n",
       "      <th>CHIS</th>\n",
       "      <th>CHIC</th>\n",
       "      <th>DHS</th>\n",
       "      <th>DHC</th>\n",
       "      <th>F10.7</th>\n",
       "      <th>...</th>\n",
       "      <th>DS</th>\n",
       "      <th>DC</th>\n",
       "      <th>IS</th>\n",
       "      <th>LATS</th>\n",
       "      <th>LATC</th>\n",
       "      <th>LONS</th>\n",
       "      <th>LONC</th>\n",
       "      <th>R_Delta_H</th>\n",
       "      <th>EqDist</th>\n",
       "      <th>foF2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>604.992</td>\n",
       "      <td>4.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>604.992</td>\n",
       "      <td>4.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>604.992</td>\n",
       "      <td>4.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>604.992</td>\n",
       "      <td>4.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-1-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>604.992</td>\n",
       "      <td>4.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661199</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.188293</td>\n",
       "      <td>856.704</td>\n",
       "      <td>5.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661200</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.188293</td>\n",
       "      <td>856.704</td>\n",
       "      <td>5.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661201</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.188293</td>\n",
       "      <td>856.704</td>\n",
       "      <td>5.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661202</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.188293</td>\n",
       "      <td>856.704</td>\n",
       "      <td>5.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661203</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.188293</td>\n",
       "      <td>856.704</td>\n",
       "      <td>5.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1661204 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date  Hour  Height         HourS  HourC      CHIS      CHIC  \\\n",
       "0          2009-1-1  20.0   150.0 -8.660254e-01    0.5  0.026620  0.999646   \n",
       "1          2009-1-1  20.0   200.0 -8.660254e-01    0.5  0.026620  0.999646   \n",
       "2          2009-1-1  20.0   250.0 -8.660254e-01    0.5  0.026620  0.999646   \n",
       "3          2009-1-1  20.0   300.0 -8.660254e-01    0.5  0.026620  0.999646   \n",
       "4          2009-1-1  20.0   350.0 -8.660254e-01    0.5  0.026620  0.999646   \n",
       "...             ...   ...     ...           ...    ...       ...       ...   \n",
       "1661199  2009-12-31  24.0  1800.0 -2.449294e-16    1.0  0.021017  0.999779   \n",
       "1661200  2009-12-31  24.0  1850.0 -2.449294e-16    1.0  0.021017  0.999779   \n",
       "1661201  2009-12-31  24.0  1900.0 -2.449294e-16    1.0  0.021017  0.999779   \n",
       "1661202  2009-12-31  24.0  1950.0 -2.449294e-16    1.0  0.021017  0.999779   \n",
       "1661203  2009-12-31  24.0  2000.0 -2.449294e-16    1.0  0.021017  0.999779   \n",
       "\n",
       "              DHS       DHC  F10.7  ...        DS        DC        IS  \\\n",
       "0        0.017452  0.999848   10.7  ...  0.001962  0.999998 -0.007707   \n",
       "1        0.017452  0.999848   10.7  ...  0.001962  0.999998 -0.007707   \n",
       "2        0.017452  0.999848   10.7  ...  0.001962  0.999998 -0.007707   \n",
       "3        0.017452  0.999848   10.7  ...  0.001962  0.999998 -0.007707   \n",
       "4        0.017452  0.999848   10.7  ...  0.001962  0.999998 -0.007707   \n",
       "...           ...       ...    ...  ...       ...       ...       ...   \n",
       "1661199  0.087156  0.996195   10.7  ...  0.000219  1.000000 -0.010192   \n",
       "1661200  0.087156  0.996195   10.7  ...  0.000219  1.000000 -0.010192   \n",
       "1661201  0.087156  0.996195   10.7  ...  0.000219  1.000000 -0.010192   \n",
       "1661202  0.087156  0.996195   10.7  ...  0.000219  1.000000 -0.010192   \n",
       "1661203  0.087156  0.996195   10.7  ...  0.000219  1.000000 -0.010192   \n",
       "\n",
       "             LATS      LATC      LONS      LONC  R_Delta_H   EqDist   foF2  \n",
       "0       -0.003339  0.999994  0.046133  0.998935   0.290759  604.992  4.361  \n",
       "1       -0.003339  0.999994  0.046133  0.998935   0.290759  604.992  4.361  \n",
       "2       -0.003339  0.999994  0.046133  0.998935   0.290759  604.992  4.361  \n",
       "3       -0.003339  0.999994  0.046133  0.998935   0.290759  604.992  4.361  \n",
       "4       -0.003339  0.999994  0.046133  0.998935   0.290759  604.992  4.361  \n",
       "...           ...       ...       ...       ...        ...      ...    ...  \n",
       "1661199 -0.004728  0.999989  0.033623  0.999435   0.188293  856.704  5.757  \n",
       "1661200 -0.004728  0.999989  0.033623  0.999435   0.188293  856.704  5.757  \n",
       "1661201 -0.004728  0.999989  0.033623  0.999435   0.188293  856.704  5.757  \n",
       "1661202 -0.004728  0.999989  0.033623  0.999435   0.188293  856.704  5.757  \n",
       "1661203 -0.004728  0.999989  0.033623  0.999435   0.188293  856.704  5.757  \n",
       "\n",
       "[1661204 rows x 23 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 stations together\n",
    "df = pd.read_csv('2009_merged_foF2.txt', sep =',', skiprows = 1)\n",
    "df.columns = ['Date', 'Hour', 'Height', 'HourS', 'HourC', 'CHIS', 'CHIC', 'DHS', 'DHC', 'F10.7', 'DST_t', 'AP_x', 'Delta_Kp', 'DS', 'DC', 'IS', 'LATS', 'LATC', 'LONS', 'LONC', 'R_Delta_H', 'EqDist','foF2']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df['HourS', 'HourC', 'CHIS', 'CHIC', 'DHS', 'DHC', 'F10.7', 'DST_t', 'AP_x', 'Delta_Kp', 'DS', 'DC', 'IS', 'LATS', 'LATC', 'LONS', 'LONC']\n",
    "X = df.drop(['Date', 'Hour', 'Height', 'foF2'], axis=1)\n",
    "y = df['foF2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "shift = 1\n",
    "X = X.to_numpy()[:-shift]\n",
    "y = y[shift:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\925014986.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  X_train, X_test, y_train, y_test = train_test_split(X[:-shift], y[shift:], test_size=0.20, random_state=42, shuffle=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332241, 19) (1328961, 19) (332241,) (1328961,)\n"
     ]
    }
   ],
   "source": [
    "#train_test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:-shift], y[shift:], test_size=0.20, random_state=42, shuffle=True)\n",
    "print(np.asarray(X_test).shape, np.asarray(X_train).shape, np.asarray(y_test).shape ,np.asarray(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:967: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sqrt(self.var_), copy=False, constant_mask=constant_mask\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler =RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.08371048e-01 -1.22744735e+00 -1.58412991e+00 ... -3.26272342e-12\n",
      "   5.52162482e-14 -1.23190347e-12]\n",
      " [-3.64373070e-01 -1.36877955e+00 -6.07942880e-01 ... -3.26272342e-12\n",
      "   5.52162482e-14 -1.23190347e-12]\n",
      " [ 1.36705139e+00  3.63904690e-01 -8.23132335e-01 ... -3.26272342e-12\n",
      "   5.52162482e-14 -1.23190347e-12]\n",
      " ...\n",
      " [ 1.51997124e-03  1.41247619e+00  9.88833090e-01 ... -3.26272342e-12\n",
      "   5.52162482e-14 -1.23190347e-12]\n",
      " [-3.64373070e-01  1.36427040e+00  1.31025663e+00 ... -3.26272342e-12\n",
      "   5.52162482e-14 -1.23190347e-12]\n",
      " [ 1.00115835e+00 -1.00262029e+00 -1.16923104e+00 ... -3.26272342e-12\n",
      "   5.52162482e-14 -1.23190347e-12]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "def printError(model_name, y_in, pred_in):\n",
    "    # Calculate ensemble metrics\n",
    "    print(model_name + ' Model Performance:')\n",
    "    _mse = mean_squared_error(y_in, pred_in)\n",
    "    _r2 = r2_score(y_in, pred_in)\n",
    "    _mae = mean_absolute_error(y_in, pred_in)\n",
    "    _mape = np.mean(np.abs((y_in - pred_in) / y_in)) * 100\n",
    "    \n",
    "    print('MSE:', _mse)\n",
    "    print('R^2:', _r2)\n",
    "    print('MAE:', _mae)\n",
    "    print('MAPE:', _mape)\n",
    "    #print('MSE:', _mse ,'\\tR^2:', _r2, '\\tMAE:', _mae, '\\tMAPE:', _mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Train: Model Performance:\n",
      "MSE: 0.07160872423197609\n",
      "R^2: 0.9831497574240304\n",
      "MAE: 0.20156567190142735\n",
      "MAPE: 4.635512653011995\n",
      "Random Forrest Test : Model Performance:\n",
      "MSE: 0.07404334139807574\n",
      "R^2: 0.982611484331706\n",
      "MAE: 0.2049281923036032\n",
      "MAPE: 4.711655833253938\n",
      "Gradient Boosting Train Model Performance:\n",
      "MSE: 0.09005486964976578\n",
      "R^2: 0.9788091965745667\n",
      "MAE: 0.22568049768129378\n",
      "MAPE: 5.2392443068145775\n",
      "Gradient Boosting Test Model Performance:\n",
      "MSE: 0.09094080489686529\n",
      "R^2: 0.9786432435249673\n",
      "MAE: 0.22676943836270536\n",
      "MAPE: 5.261018277189617\n",
      "MLP Train Model Performance:\n",
      "MSE: 0.0683713215555738\n",
      "R^2: 0.9839115503619518\n",
      "MAE: 0.19169040726688855\n",
      "MAPE: 4.42087876856031\n",
      "MLP Test : Model Performance:\n",
      "MSE: 0.06917799114294847\n",
      "R^2: 0.9837540748407996\n",
      "MAE: 0.19248166246200882\n",
      "MAPE: 4.434533227793496\n",
      "CatBoost Train Model Performance:\n",
      "MSE: 0.06677792848290222\n",
      "R^2: 0.9842864915451853\n",
      "MAE: 0.18988757691274466\n",
      "MAPE: 4.360386480000386\n",
      "CatBoost Test : Model Performance:\n",
      "MSE: 0.06874147718539739\n",
      "R^2: 0.983856586824281\n",
      "MAE: 0.19240438675494337\n",
      "MAPE: 4.413458509006269\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\2088703115.py:81: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  history = model.fit(X_ensembleTrain, y_train[1:], epochs=50, batch_size=32, validation_split=0.2)\n",
      "d:\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.1211 - val_loss: 0.0759\n",
      "Epoch 2/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0698 - val_loss: 0.0691\n",
      "Epoch 3/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0691 - val_loss: 0.0698\n",
      "Epoch 4/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0691 - val_loss: 0.0755\n",
      "Epoch 5/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0690 - val_loss: 0.0688\n",
      "Epoch 6/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0688 - val_loss: 0.0690\n",
      "Epoch 7/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0689 - val_loss: 0.0697\n",
      "Epoch 8/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0688 - val_loss: 0.0693\n",
      "Epoch 9/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0687 - val_loss: 0.0697\n",
      "Epoch 10/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0686 - val_loss: 0.0690\n",
      "Epoch 11/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0685 - val_loss: 0.0698\n",
      "Epoch 12/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0685 - val_loss: 0.0689\n",
      "Epoch 13/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0684 - val_loss: 0.0692\n",
      "Epoch 14/50\n",
      "6813/6813 [==============================] - 13s 2ms/step - loss: 0.0685 - val_loss: 0.0688\n",
      "Epoch 15/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0685 - val_loss: 0.0696\n",
      "Epoch 16/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0684 - val_loss: 0.0697\n",
      "Epoch 17/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0684 - val_loss: 0.0689\n",
      "Epoch 18/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0685 - val_loss: 0.0738\n",
      "Epoch 19/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0684 - val_loss: 0.0733\n",
      "Epoch 20/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0682 - val_loss: 0.0689\n",
      "Epoch 21/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0684 - val_loss: 0.0697\n",
      "Epoch 22/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0683 - val_loss: 0.0717\n",
      "Epoch 23/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0713\n",
      "Epoch 24/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0681 - val_loss: 0.0728\n",
      "Epoch 25/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0695\n",
      "Epoch 26/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0695\n",
      "Epoch 27/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0700\n",
      "Epoch 28/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0683 - val_loss: 0.0694\n",
      "Epoch 29/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0681 - val_loss: 0.0689\n",
      "Epoch 30/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0753\n",
      "Epoch 31/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0689\n",
      "Epoch 32/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0681 - val_loss: 0.0697\n",
      "Epoch 33/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0681 - val_loss: 0.0688\n",
      "Epoch 34/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0681 - val_loss: 0.0689\n",
      "Epoch 35/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0681 - val_loss: 0.0687\n",
      "Epoch 36/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0682 - val_loss: 0.0693\n",
      "Epoch 37/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0693\n",
      "Epoch 38/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0703\n",
      "Epoch 39/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0698\n",
      "Epoch 40/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0690\n",
      "Epoch 41/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0687\n",
      "Epoch 42/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0679 - val_loss: 0.0687\n",
      "Epoch 43/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0679 - val_loss: 0.0688\n",
      "Epoch 44/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0680 - val_loss: 0.0724\n",
      "Epoch 45/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0680 - val_loss: 0.0688\n",
      "Epoch 46/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0710\n",
      "Epoch 47/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0680 - val_loss: 0.0688\n",
      "Epoch 48/50\n",
      "6813/6813 [==============================] - 11s 2ms/step - loss: 0.0680 - val_loss: 0.0689\n",
      "Epoch 49/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0679 - val_loss: 0.0692\n",
      "Epoch 50/50\n",
      "6813/6813 [==============================] - 12s 2ms/step - loss: 0.0680 - val_loss: 0.0707\n",
      "8517/8517 [==============================] - 9s 1ms/step\n",
      "2130/2130 [==============================] - 2s 1ms/step\n",
      "CNN Train  Model Performance:\n",
      "MSE: 0.06913554222223048\n",
      "R^2: 0.983731713250426\n",
      "MAE: 0.19686250664533786\n",
      "MAPE: 4.469364093978764\n",
      "CNN Test  Model Performance:\n",
      "MSE: 0.0704718627286108\n",
      "R^2: 0.9834501675052227\n",
      "MAE: 0.19850752282182535\n",
      "MAPE: 4.501424902439184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\2088703115.py:87: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  printError(\"CNN Train \",  y_train[1:].to_numpy().flatten(), nnTrain_pred.flatten())\n",
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\2088703115.py:88: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  printError(\"CNN Test \",  y_test[1:].to_numpy().flatten(), nn_pred.flatten())\n"
     ]
    }
   ],
   "source": [
    "#Convolutional Neural Networks (CNN) ***** without errors*****\n",
    "# Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_predTrain = rf.predict(X_train) \n",
    "rf_errorTrain = y_train - rf_predTrain\n",
    "printError(\"Random Forrest Train:\", y_train, rf_predTrain)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_error = y_test - rf_pred\n",
    "printError(\"Random Forrest Test :\", y_test, rf_pred)\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_predTrain = gb.predict(X_train) \n",
    "gb_errorTrain = y_train - gb_predTrain\n",
    "printError(\"Gradient Boosting Train\", y_train, gb_predTrain)\n",
    "\n",
    "gb_pred = gb.predict(X_test)\n",
    "gb_error = y_test - gb_pred\n",
    "printError(\"Gradient Boosting Test\", y_test, gb_pred)\n",
    "\n",
    "# MLP model\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_predTrain = mlp.predict(X_train)\n",
    "mlp_errorTrain = y_train - mlp_predTrain\n",
    "printError(\"MLP Train\", y_train, mlp_predTrain)\n",
    "\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "mlp_error = y_test - mlp_pred\n",
    "printError(\"MLP Test :\", y_test, mlp_pred)\n",
    "\n",
    "# CatBoost model\n",
    "catboost = CatBoostRegressor(iterations=1000, learning_rate=0.1, random_seed=42)\n",
    "catboost.fit(X_train, y_train, silent=True)\n",
    "catboost_predTrain = catboost.predict(X_train) \n",
    "catboost_errorTrain = y_train - catboost_predTrain\n",
    "printError(\"CatBoost Train\", y_train, catboost_predTrain)\n",
    "\n",
    "catboost_pred = catboost.predict(X_test)\n",
    "catboost_error = y_test - catboost_pred\n",
    "printError(\"CatBoost Test :\", y_test, catboost_pred)\n",
    "\n",
    "\n",
    "# Combine errors from previous models\n",
    "#error_dfTrain = pd.DataFrame({'rf_error': rf_errorTrain[:-1], 'gb_error': gb_errorTrain[:-1], 'mlp_error': mlp_errorTrain[:-1], 'catboost_error': catboost_errorTrain[:-1]})\n",
    "\n",
    "\n",
    "#print(error_dfTrain.shape)\n",
    "\n",
    "#error_df = pd.DataFrame({'rf_error': rf_error[:-1], 'gb_error': gb_error[:-1], 'mlp_error': mlp_error[:-1], 'catboost_error': catboost_error[:-1]})\n",
    "\n",
    "\n",
    "#print(error_df.shape)\n",
    "\n",
    "# Ensemble model\n",
    "\n",
    "X_ensembleTrain = np.column_stack((rf_predTrain[1:], gb_predTrain[1:], mlp_predTrain[1:], catboost_predTrain[1:]))\n",
    "\n",
    "X_ensemble = np.column_stack((rf_pred[1:], gb_pred[1:], mlp_pred[1:], catboost_pred[1:]))\n",
    "\n",
    "\n",
    "# Reshape the input data from 2D to 3D\n",
    "X_ensembleTrain = np.reshape(X_ensembleTrain, (X_ensembleTrain.shape[0], X_ensembleTrain.shape[1], 1))\n",
    "X_ensemble = np.reshape(X_ensemble, (X_ensemble.shape[0], X_ensemble.shape[1], 1))\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_ensembleTrain.shape[1], 1)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_ensembleTrain, y_train[1:], epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the training and test sets\n",
    "nnTrain_pred = model.predict(X_ensembleTrain)\n",
    "nn_pred = model.predict(X_ensemble)\n",
    "\n",
    "printError(\"CNN Train \",  y_train[1:].to_numpy().flatten(), nnTrain_pred.flatten())\n",
    "printError(\"CNN Test \",  y_test[1:].to_numpy().flatten(), nn_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Train: Model Performance:\n",
      "MSE: 0.0812172641933355\n",
      "R^2: 0.9872625770718033\n",
      "MAE: 0.18769895222635602\n",
      "MAPE: 3.953949890355875\n",
      "Random Forrest Test : Model Performance:\n",
      "MSE: 0.08106612806559825\n",
      "R^2: 0.9872792379588048\n",
      "MAE: 0.18792927814054097\n",
      "MAPE: 3.965783451030753\n",
      "Gradient Boosting Train Model Performance:\n",
      "MSE: 0.1906146941636499\n",
      "R^2: 0.9701056173215633\n",
      "MAE: 0.33197002631459693\n",
      "MAPE: 7.195496960096391\n",
      "Gradient Boosting Test Model Performance:\n",
      "MSE: 0.18983790742328285\n",
      "R^2: 0.970210951178328\n",
      "MAE: 0.3317604805789837\n",
      "MAPE: 7.190807475906391\n",
      "MLP Train Model Performance:\n",
      "MSE: 0.03333528724897995\n",
      "R^2: 0.9947719778997675\n",
      "MAE: 0.08424588851099364\n",
      "MAPE: 1.8655403292709358\n",
      "MLP Test : Model Performance:\n",
      "MSE: 0.03265994163263621\n",
      "R^2: 0.9948750562571349\n",
      "MAE: 0.0839090689090401\n",
      "MAPE: 1.8621505820260384\n",
      "CatBoost Train Model Performance:\n",
      "MSE: 0.030813082839936362\n",
      "R^2: 0.9951675389247348\n",
      "MAE: 0.07371442278100822\n",
      "MAPE: 1.6221285391664966\n",
      "CatBoost Test : Model Performance:\n",
      "MSE: 0.03023619048919669\n",
      "R^2: 0.9952553872570048\n",
      "MAE: 0.07339668083077382\n",
      "MAPE: 1.6213672396332333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\2007303526.py:48: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  error_dfTrain = pd.DataFrame({'rf_error': rf_errorTrain[:-1], 'gb_error': gb_errorTrain[:-1], 'mlp_error': mlp_errorTrain[:-1], 'catboost_error': catboost_errorTrain[:-1]})\n",
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\2007303526.py:53: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  error_df = pd.DataFrame({'rf_error': rf_error[:-1], 'gb_error': gb_error[:-1], 'mlp_error': mlp_error[:-1], 'catboost_error': catboost_error[:-1]})\n",
      "d:\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\UYSM12\\AppData\\Local\\Temp\\ipykernel_10124\\2007303526.py:81: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  history = model.fit(X_ensembleTrain, y_train[1:], epochs=50, batch_size=32, validation_split=0.2)\n",
      "d:\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33224/33224 [==============================] - 75s 2ms/step - loss: 0.0465 - val_loss: 0.0306\n",
      "Epoch 2/50\n",
      "33224/33224 [==============================] - 76s 2ms/step - loss: 0.0317 - val_loss: 0.0315\n",
      "Epoch 3/50\n",
      "33224/33224 [==============================] - 75s 2ms/step - loss: 0.0315 - val_loss: 0.0307\n",
      "Epoch 4/50\n",
      "33224/33224 [==============================] - 74s 2ms/step - loss: 0.0315 - val_loss: 0.0313\n",
      "Epoch 5/50\n",
      " 7482/33224 [=====>........................] - ETA: 51s - loss: 0.0313"
     ]
    }
   ],
   "source": [
    "#******Convolutional Neural Networks (CNN) *******with errors*******\n",
    "# Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_predTrain = rf.predict(X_train) \n",
    "rf_errorTrain = y_train - rf_predTrain\n",
    "printError(\"Random Forrest Train:\", y_train, rf_predTrain)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_error = y_test - rf_pred\n",
    "printError(\"Random Forrest Test :\", y_test, rf_pred)\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_predTrain = gb.predict(X_train) \n",
    "gb_errorTrain = y_train - gb_predTrain\n",
    "printError(\"Gradient Boosting Train\", y_train, gb_predTrain)\n",
    "\n",
    "gb_pred = gb.predict(X_test)\n",
    "gb_error = y_test - gb_pred\n",
    "printError(\"Gradient Boosting Test\", y_test, gb_pred)\n",
    "\n",
    "# MLP model\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_predTrain = mlp.predict(X_train)\n",
    "mlp_errorTrain = y_train - mlp_predTrain\n",
    "printError(\"MLP Train\", y_train, mlp_predTrain)\n",
    "\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "mlp_error = y_test - mlp_pred\n",
    "printError(\"MLP Test :\", y_test, mlp_pred)\n",
    "\n",
    "# CatBoost model\n",
    "catboost = CatBoostRegressor(iterations=1000, learning_rate=0.1, random_seed=42)\n",
    "catboost.fit(X_train, y_train, silent=True)\n",
    "catboost_predTrain = catboost.predict(X_train) \n",
    "catboost_errorTrain = y_train - catboost_predTrain\n",
    "printError(\"CatBoost Train\", y_train, catboost_predTrain)\n",
    "\n",
    "catboost_pred = catboost.predict(X_test)\n",
    "catboost_error = y_test - catboost_pred\n",
    "printError(\"CatBoost Test :\", y_test, catboost_pred)\n",
    "\n",
    "\n",
    "# Combine errors from previous models\n",
    "error_dfTrain = pd.DataFrame({'rf_error': rf_errorTrain[:-1], 'gb_error': gb_errorTrain[:-1], 'mlp_error': mlp_errorTrain[:-1], 'catboost_error': catboost_errorTrain[:-1]})\n",
    "#error_dfTrain = pd.DataFrame({'rf_error': rf_errorTrain[:-1], 'gb_error': gb_errorTrain[:-1], 'catboost_error': catboost_errorTrain[:-1]})\n",
    "\n",
    "#print(error_dfTrain.shape)\n",
    "\n",
    "error_df = pd.DataFrame({'rf_error': rf_error[:-1], 'gb_error': gb_error[:-1], 'mlp_error': mlp_error[:-1], 'catboost_error': catboost_error[:-1]})\n",
    "#error_df = pd.DataFrame({'rf_error': rf_error[:-1], 'gb_error': gb_error[:-1], 'catboost_error': catboost_error[:-1]})\n",
    "\n",
    "#print(error_df.shape)\n",
    "\n",
    "# Ensemble model\n",
    "\n",
    "X_ensembleTrain = np.column_stack((rf_predTrain[1:], gb_predTrain[1:], mlp_predTrain[1:], catboost_predTrain[1:], error_dfTrain))\n",
    "#X_ensembleTrain = np.column_stack((rf_predTrain[1:], gb_predTrain[1:], catboost_predTrain[1:], error_dfTrain))\n",
    "X_ensemble = np.column_stack((rf_pred[1:], gb_pred[1:], mlp_pred[1:], catboost_pred[1:], error_df))\n",
    "#X_ensemble = np.column_stack((rf_pred[1:], gb_pred[1:], catboost_pred[1:], error_df))\n",
    "\n",
    "# Reshape the input data from 2D to 3D\n",
    "X_ensembleTrain = np.reshape(X_ensembleTrain, (X_ensembleTrain.shape[0], X_ensembleTrain.shape[1], 1))\n",
    "X_ensemble = np.reshape(X_ensemble, (X_ensemble.shape[0], X_ensemble.shape[1], 1))\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_ensembleTrain.shape[1], 1)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_ensembleTrain, y_train[1:], epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the training and test sets\n",
    "nnTrain_pred = model.predict(X_ensembleTrain)\n",
    "nn_pred = model.predict(X_ensemble)\n",
    "\n",
    "printError(\"CNN Train \",  y_train[1:].to_numpy().flatten(), nnTrain_pred.flatten())\n",
    "printError(\"CNN Test \",  y_test[1:].to_numpy().flatten(), nn_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50ca854c4c3efc08975ea3cb237e66ea0431a08d0f81600bb6a2a9be70ab2e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
