{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os \n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Flatten, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations' data preparation\n",
    " \n",
    "hour_intervals=[1,2,6,12,18,24,]   # end of this cell 0 is added for original input dataset\n",
    "hour_steps_for_height=39 #39 is the number of different heights\n",
    "\n",
    "result_folder=\"results and todos \\\\\"\n",
    "data_folder=\"data\\\\\"\n",
    "stations=[\"BJNM2009_foF2.txt\",\"ISTA2009_foF2.txt\",\"KGNI2009_foF2.txt\",\"NRIL2009_foF2.txt\",\"WUHN2009_foF2.txt\",\\\n",
    "          \"BJNM2012_foF2.txt\",\"ISTA2012_foF2.txt\",\"KGNI2012_foF2.txt\",\"NRIL2012_foF2.txt\",\"WUHN2012_foF2.txt\",\\\n",
    "          \"BJNM2015_foF2.txt\",\"ISTA2015_foF2.txt\",\"KGNI2015_foF2.txt\",\"NRIL2015_foF2.txt\",\"WUHN2015_foF2.txt\",\\\n",
    "          \"BJNM2019_foF2.txt\",\"ISTA2019_foF2.txt\",\"KGNI2019_foF2.txt\",\"NRIL2019_foF2.txt\",\"WUHN2019_foF2.txt\"]\n",
    "\n",
    "stations_data={}\n",
    "\n",
    "for st in stations:\n",
    "    stations_data[st]=pd.read_csv(data_folder+st, sep =',').iloc[::hour_steps_for_height]\n",
    "    print(\"\\n\\n--------------------------\"+st+\"--------------------------------------\\n\")\n",
    "    print(stations_data[st].shape)\n",
    "    print(stations_data[st].head(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input-Output data preparation,split and scaling for ML Models\n",
    "\n",
    "X_train_base,X_val_base,X_test_base, y_train_base,y_val_base, y_test_base={},{},{},{},{},{}\n",
    "\n",
    "num_fold=4\n",
    "\n",
    "train_ratio=0.8\n",
    "val_ratio=0.1\n",
    "test_ratio=0.1\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for st in stations_data:\n",
    "    \n",
    "    X, y = {}, {}\n",
    "    X[st] = stations_data[st].drop(['Date','Hour','DOY','Height','F10.7','EqDistance','foF2'], axis=1).to_numpy()\n",
    "    y[st] = stations_data[st]['foF2'].to_numpy()\n",
    "\n",
    "    # k-fold train_test split \n",
    "    X_train_base[st],X_val_base[st],X_test_base[st], y_train_base[st],y_val_base[st], y_test_base[st] \\\n",
    "        = np.empty((0,X[st].shape[1])),np.empty((0,X[st].shape[1])),np.empty((0,X[st].shape[1])),np.empty((0,)),np.empty((0,)),np.empty((0,))\n",
    "\n",
    "    for i in range(num_fold):\n",
    "\n",
    "        len_fold=int(X[st].shape[0]/num_fold)\n",
    "        split_index_train = len_fold*i+int(train_ratio * len_fold)\n",
    "        split_index_val = split_index_train+int(val_ratio * len_fold)\n",
    "\n",
    "\n",
    "        X_train_base[st]=np.vstack([X_train_base[st],X[st][i*len_fold:split_index_train]])\n",
    "        y_train_base[st]=np.hstack([y_train_base[st],y[st][i*len_fold:split_index_train]])\n",
    "        \n",
    "        X_val_base[st]=np.vstack([X_val_base[st],X[st][split_index_train:split_index_val]])\n",
    "        y_val_base[st]=np.hstack([y_val_base[st],y[st][split_index_train:split_index_val]])\n",
    "        \n",
    "        X_test_base[st]=np.vstack([X_test_base[st],X[st][split_index_val:(i+1)*len_fold]])\n",
    "        y_test_base[st]=np.hstack([y_test_base[st],y[st][split_index_val:(i+1)*len_fold]])\n",
    "\n",
    "\n",
    "    #shapes\n",
    "    print(st)\n",
    "    print(\"Train: \",X_train_base[st].shape,y_train_base[st].shape,\"Validation:\",X_val_base[st].shape,y_val_base[st].shape,\"Test: \",X_test_base[st].shape,y_test_base[st].shape,\"\\n\")\n",
    "    \n",
    "    #scaling\n",
    "    scaler.fit(X_train_base[st])\n",
    "    X_train_base[st] = scaler.transform(X_train_base[st])\n",
    "    X_val_base[st] = scaler.transform(X_val_base[st])\n",
    "    X_test_base[st] = scaler.transform(X_test_base[st])\n",
    "\n",
    "    print(\"Scaled X_train: \",X_train_base[st][0],\"\\n\") #prints first row of X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print or save results\n",
    "result_array = [['Train', 'Train', 'Train', 'Train','Validation', 'Validation', 'Validation', 'Validation', 'Test', 'Test', 'Test', 'Test'],\n",
    "          ['RMSE', 'R2', 'MAE', 'MAPE','RMSE', 'R2', 'MAE', 'MAPE','RMSE', 'R2', 'MAE', 'MAPE']]\n",
    "results_df=pd.DataFrame(index=pd.MultiIndex.from_arrays(result_array,names=[\"ExperimentData\",\"Metric\"]))\n",
    "save_row_index=0\n",
    "save_column_index=0\n",
    "\n",
    "\n",
    "def save_error_to_df(model_name, data_type, mse_result,r2_result,mae_result,mape_result):\n",
    "    \n",
    "    results_df.loc[(data_type, 'RMSE'), model_name] = mse_result\n",
    "    results_df.loc[(data_type, 'R2'), model_name] = r2_result\n",
    "    results_df.loc[(data_type, 'MAE'), model_name] = mae_result\n",
    "    results_df.loc[(data_type, 'MAPE'), model_name] = mape_result\n",
    "\n",
    "def printError(model_name, data_type, y_in, pred_in):\n",
    "    # Calculate ensemble metrics\n",
    "    print(\"\\n\",model_name + \" \" + data_type +' Model Performance:'+\"\\n\")\n",
    "    _rmse = np.sqrt(mean_squared_error(y_in, pred_in))\n",
    "    _r2 = r2_score(y_in, pred_in)\n",
    "    _mae = mean_absolute_error(y_in, pred_in)\n",
    "    _mape = np.mean(np.abs((y_in - pred_in) / y_in)) * 100\n",
    "    \n",
    "    print('RMSE:', _rmse)\n",
    "    print('R^2:', _r2)\n",
    "    print('MAE:', _mae)\n",
    "    print('MAPE:', _mape)\n",
    "\n",
    "    save_error_to_df(model_name,data_type,round(_rmse,2),round(_r2,2),round(_mae,2),round(_mape,2))\n",
    "\n",
    "def save_error_to_excel(st_result_header,first_run):\n",
    "    global save_row_index\n",
    "    global save_column_index\n",
    "    st_header_df=pd.DataFrame(data=st_result_header)\n",
    "\n",
    "    if first_run:\n",
    "        #Export all results to an excel file\n",
    "        st_header_df.to_excel(result_folder+\"foF2_ML_Experiments.xlsx\",startrow=save_row_index,startcol=save_column_index,index=False,header=False)\n",
    "        save_row_index+=1\n",
    "      \n",
    "        with pd.ExcelWriter(result_folder+\"foF2_ML_Experiments.xlsx\", mode=\"a\",if_sheet_exists=\"overlay\") as writer:\n",
    "            results_df.to_excel(writer,startrow=save_row_index,startcol=save_column_index)\n",
    "        save_row_index+=16\n",
    "    else :\n",
    "        with pd.ExcelWriter(result_folder+\"foF2_ML_Experiments.xlsx\", mode=\"a\",if_sheet_exists=\"overlay\") as writer:\n",
    "            st_header_df.to_excel(writer,startrow=save_row_index,startcol=save_column_index,index=False,header=False)\n",
    "            save_row_index+=1\n",
    "            results_df.to_excel(writer,startrow=save_row_index,startcol=save_column_index)\n",
    "            save_row_index+=16\n",
    "\n",
    "def generate_mape_elem(st, model, mape):\n",
    "    my_dict = {\n",
    "        \"st\": st,\n",
    "        \"model\": model,\n",
    "        \"mape\": mape\n",
    "    }\n",
    "    return my_dict\n",
    "\n",
    "def generate_lstm_result(st, hour,y_real,y_pred):\n",
    "    my_dict = {\n",
    "        \"st\": st,\n",
    "        \"hour\": hour,\n",
    "        \"real\": y_real,\n",
    "        \"pred\": y_pred\n",
    "    }\n",
    "    return my_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run=True\n",
    "mape_result_array=[]\n",
    "lstm_results=[]\n",
    "\n",
    "for hour_interval in hour_intervals:\n",
    "    \n",
    "    for st in stations_data:\n",
    "\n",
    "        st_result_header=[st[:st.rfind('_')]+\"_\"+str(hour_interval)+\"h\"] #Results' header\n",
    "\n",
    "        # data preparation for different hours\n",
    "\n",
    "        X_train = X_train_base.copy()[st][:-hour_interval]\n",
    "        X_test = X_test_base.copy()[st][:-hour_interval]\n",
    "        X_val = X_val_base.copy()[st][:-hour_interval]\n",
    "\n",
    "        y_train = y_train_base.copy()[st][hour_interval:]\n",
    "        y_test = y_test_base.copy()[st][hour_interval:]\n",
    "        y_val = y_val_base.copy()[st][hour_interval:]\n",
    "        \n",
    "        print(\"\\nSTATION: \",st[:-9],\" HOUR: \",hour_interval)\n",
    "\n",
    "        #Linear Regression Model\n",
    "\n",
    "        reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        reg_predTrain = reg.predict(X_train) \n",
    "        reg_errorTrain = y_train - reg_predTrain\n",
    "        printError(\"Linear Regression\",\"Train\", y_train, reg_predTrain)\n",
    "\n",
    "        reg_predVal = reg.predict(X_val) \n",
    "        reg_errorVal = y_val - reg_predVal\n",
    "        printError(\"Linear Regression\",\"Validation\", y_val, reg_predVal)\n",
    "\n",
    "        reg_predTest = reg.predict(X_test)\n",
    "        reg_errorTest = y_test - reg_predTest\n",
    "        printError(\"Linear Regression\",\"Test\", y_test, reg_predTest)\n",
    "\n",
    "        mape_result_array.append(generate_mape_elem(st,\"Linear Regression\",np.mean(np.abs(reg_errorTest / y_test)) * 100))\n",
    "\n",
    "\n",
    "         #Decision Tree Model \n",
    "        dectree = DecisionTreeRegressor(max_depth=12,min_samples_leaf=5,random_state=44).fit(X_train, y_train)\n",
    "\n",
    "        dectree_predTrain = dectree.predict(X_train) \n",
    "        dectree_errorTrain = y_train-dectree_predTrain\n",
    "        printError(\"Decision Tree\",\"Train\", y_train ,dectree_predTrain)\n",
    "\n",
    "        dectree_predVal = dectree.predict(X_val) \n",
    "        dectree_errorVal = y_val - dectree_predVal\n",
    "        printError(\"Decision Tree\",\"Validation\", y_val, dectree_predVal)\n",
    "\n",
    "        dectree_predTest = dectree.predict(X_test)\n",
    "        dectree_errorTest = y_test - dectree_predTest\n",
    "        printError(\"Decision Tree\",\"Test\", y_test, dectree_predTest)\n",
    "\n",
    "        mape_result_array.append(generate_mape_elem(st,\"Decision Tree\",np.mean(np.abs(dectree_errorTest / y_test)) * 100))\n",
    "\n",
    "        # MLP model\n",
    "\n",
    "        #default parameters= loss:mse, learning_rate:adaptive, batch:200\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(12,4), activation='relu',batch_size=72, solver='adam', max_iter=1000,shuffle=False,random_state=44)\n",
    "        mlp.fit(X_train, y_train)\n",
    "\n",
    "        mlp_predTrain = mlp.predict(X_train)\n",
    "        mlp_errorTrain = y_train - mlp_predTrain\n",
    "        printError(\"MLP\",\"Train\", y_train, mlp_predTrain)\n",
    "\n",
    "        mlp_predVal = mlp.predict(X_val)\n",
    "        mlp_errorVal = y_val - mlp_predVal\n",
    "        printError(\"MLP\",\"Validation\", y_val, mlp_predVal)\n",
    "\n",
    "        mlp_predTest = mlp.predict(X_test)\n",
    "        mlp_errorTest = y_test- mlp_predTest\n",
    "        printError(\"MLP\",\"Test\",y_test, mlp_predTest)\n",
    "\n",
    "        mape_result_array.append(generate_mape_elem(st,\"MLP\",np.mean(np.abs(mlp_errorTest / y_test)) * 100))\n",
    "\n",
    "\n",
    "        #LSTM Model\n",
    "\n",
    "        X_lstm_train = np.expand_dims(X_train, axis = 2)\n",
    "        X_lstm_val = np.expand_dims(X_val, axis = 2)\n",
    "        X_lstm_test = np.expand_dims(X_test, axis = 2)\n",
    "        \n",
    "        y_lstm_train = np.expand_dims(y_train, axis = 1)\n",
    "        y_lstm_val = np.expand_dims(y_val, axis = 1)\n",
    "        y_lstm_test = np.expand_dims(y_test, axis = 1)\n",
    "\n",
    "        model_lstm = Sequential()\n",
    "        model_lstm.add(LSTM(36, activation='relu', input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2])))\n",
    "        model_lstm.add(Dense(12))\n",
    "        model_lstm.add(Dense(1))\n",
    "        model_lstm.compile(optimizer=Adam(0.001), loss='mae')\n",
    "\n",
    "        lstm_history = model_lstm.fit(X_lstm_train, y_lstm_train, epochs=200,batch_size=15, verbose=2, use_multiprocessing=True)\n",
    "        \n",
    "        lstm_predTrain = model_lstm.predict(X_lstm_train) \n",
    "        lstm_errorTrain = y_lstm_train - lstm_predTrain\n",
    "        printError(\"LSTM\",\"Train\", y_lstm_train, lstm_predTrain)\n",
    "\n",
    "        lstm_predVal = model_lstm.predict(X_lstm_val) \n",
    "        lstm_errorVal = y_lstm_val - lstm_predVal\n",
    "        printError(\"LSTM\",\"Validation\", y_lstm_val, lstm_predVal)\n",
    "\n",
    "        lstm_predTest = model_lstm.predict(X_lstm_test)\n",
    "        lstm_errorTest = y_lstm_test - lstm_predTest\n",
    "        printError(\"LSTM\",\"Test\", y_lstm_test, lstm_predTest)\n",
    "\n",
    "        mape_result_array.append(generate_mape_elem(st,\"LSTM\",np.mean(np.abs(lstm_errorTest / y_lstm_test)) * 100))\n",
    "        lstm_results.append(generate_lstm_result(st,hour_interval,y_lstm_test,lstm_predTest))\n",
    "\n",
    "\n",
    "        save_error_to_excel(st_result_header,first_run)\n",
    "        first_run=False\n",
    "    \n",
    "\n",
    "    save_column_index+=10\n",
    "    save_row_index=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMAPEFromResults(st):\n",
    "\n",
    "    decision_tree_results=[]\n",
    "    mlp_results=[]\n",
    "    linear_regression_results=[]\n",
    "    lstm_results=[]\n",
    "    \n",
    "    for result_dict in mape_result_array:\n",
    "        if result_dict[\"st\"] == st:\n",
    "            if result_dict[\"model\"] == \"Decision Tree\":\n",
    "                decision_tree_results.append(result_dict[\"mape\"])\n",
    "            if result_dict[\"model\"] == \"MLP\":\n",
    "                mlp_results.append(result_dict[\"mape\"]) \n",
    "            if result_dict[\"model\"] == \"Linear Regression\":\n",
    "                linear_regression_results.append(result_dict[\"mape\"])\n",
    "            if result_dict[\"model\"] == \"LSTM\":\n",
    "                lstm_results.append(result_dict[\"mape\"])\n",
    "    \n",
    "    plt.figure(figsize=(5,3))\n",
    "    \n",
    "    plt.plot([\"1\",\"2\",\"6\",\"12\",\"18\",\"24\"],linear_regression_results,c='r', label=\"Lineer Regression\")\n",
    "    plt.plot([\"1\",\"2\",\"6\",\"12\",\"18\",\"24\"],mlp_results,c='g', label=\"MLP\")\n",
    "    plt.plot([\"1\",\"2\",\"6\",\"12\",\"18\",\"24\"],decision_tree_results,c='b', label=\"Decision Tree\")\n",
    "    plt.plot([\"1\",\"2\",\"6\",\"12\",\"18\",\"24\"],lstm_results,c='y', label=\"LSTM\")\n",
    "    \n",
    "    plt.title(st[:st.find('2')] + \"  \" + st[st.find('2'):st.rfind('_')] + \" MAPEs\")\n",
    "    plt.legend(fontsize=\"small\")\n",
    "    plt.savefig(\"graphs/\"+st[:st.find('2')] + \"  \" + st[st.find('2'):st.rfind('_')] + \" MAPEs\",dpi=500,bbox_inches='tight')   \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plots hard-coded station lstm results,needs to be generalized\n",
    "def plot_lstm_preds(st):\n",
    "\n",
    "    lstm1_real,lstm6_real,lstm24_real,lstm1_pred,lstm6_pred,lstm24_pred=[],[],[],[],[],[]\n",
    "\n",
    "    \n",
    "    hour_list=stations_data[st][\"Hour\"][-120:].astype(int)\n",
    "    mm_dd_list=stations_data[st][\"Date\"][-120:].astype(str)\n",
    "    mm_dd_hh_list= [s1+\",\"+str(s2) for s1, s2 in zip(mm_dd_list, hour_list)]\n",
    "\n",
    "    step_size = len(mm_dd_hh_list) // 5  # We want to show only ten elements, so divide the total number of elements by 10\n",
    "    x_ticks_positions = list(range(0, len(mm_dd_hh_list), step_size))\n",
    "    x_ticks_labels = [day[:-2] for day in mm_dd_hh_list[::step_size]]\n",
    "    \n",
    "    \n",
    "    font = {'family': 'serif',\n",
    "    'color':  'darkred',\n",
    "    'weight': 'normal',\n",
    "    'size': 20\n",
    "    }\n",
    "\n",
    "    plt.style.use('default')\n",
    "\n",
    "    for result_dict in lstm_results:\n",
    "        if (result_dict[\"st\"] == st) & (result_dict[\"hour\"] == 1):\n",
    "            lstm1_real=result_dict[\"real\"]\n",
    "            lstm1_pred=result_dict[\"pred\"]\n",
    "        if (result_dict[\"st\"] == st) & (result_dict[\"hour\"] == 6):\n",
    "            lstm6_real=result_dict[\"real\"]\n",
    "            lstm6_pred=result_dict[\"pred\"]\n",
    "        if (result_dict[\"st\"] == st) & (result_dict[\"hour\"] == 24):\n",
    "            lstm24_real=result_dict[\"real\"]\n",
    "            lstm24_pred=result_dict[\"pred\"]\n",
    "        \n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(3,1, sharex=False, sharey=False, figsize=(20,21))\n",
    "\n",
    "    #-120 means last five days\n",
    "    ax1.plot(mm_dd_hh_list,lstm1_pred[-120:] , '-s', markersize=4, c=\"b\", linewidth=2.2, label=\"Predicted\")\n",
    "    ax1.plot(mm_dd_hh_list,lstm1_real[-120:], '-o', markersize=4, c=\"r\", linewidth=2.2,  label=\"Measured\")\n",
    "    \n",
    "    ax2.plot(mm_dd_hh_list,lstm6_pred[-120:] , '-s', markersize=4, c=\"b\", linewidth=2.2, label=\"Predicted\")\n",
    "    ax2.plot(mm_dd_hh_list,lstm6_real[-120:] , '-o', markersize=4, c=\"r\", linewidth=2.2,  label=\"Measured\")\n",
    "\n",
    "    ax3.plot(mm_dd_hh_list,lstm24_pred[-120:] , '-s', markersize=4, c=\"b\", linewidth=2.2, label=\"Predicted\")\n",
    "    ax3.plot(mm_dd_hh_list,lstm24_real[-120:],  '-o', markersize=4, c=\"r\", linewidth=2.2,  label=\"Measured\")\n",
    "\n",
    "    title = st[:st.find('2')] + \"  \" + st[st.find('2'):st.rfind('_')]\n",
    "    ax1.set_title(title + ' 1-h ahead foF2 prediction', fontdict=font)\n",
    "    ax2.set_title(title + ' 12-h ahead foF2 prediction', fontdict=font)\n",
    "    ax3.set_title(title +' 24-h ahead foF2 prediction', fontdict=font)\n",
    "\n",
    "    ax1.set_ylabel('foF2 (MHz)', fontsize = 24)\n",
    "    ax2.set_ylabel('foF2 (MHz)', fontsize = 24)\n",
    "    ax3.set_ylabel('foF2 (MHz)', fontsize = 24)\n",
    "\n",
    "    ax3.set_xlabel('Date (mm-dd,hh)', fontsize = 24)\n",
    "\n",
    "    ax1.grid(True, linestyle='-.')\n",
    "    ax2.grid(True, linestyle='-.')\n",
    "    ax3.grid(True, linestyle='--')\n",
    "\n",
    "    # Set the tick positions and labels for the x-axis\n",
    "    ax1.set_xticks(x_ticks_positions, x_ticks_labels)\n",
    "    ax2.set_xticks(x_ticks_positions, x_ticks_labels)\n",
    "    ax3.set_xticks(x_ticks_positions, x_ticks_labels)\n",
    "\n",
    "    ax1.tick_params(labelcolor='0', labelsize='14', width=1)\n",
    "    ax2.tick_params(labelcolor='0', labelsize='14', width=1)\n",
    "    ax3.tick_params(labelcolor='0', labelsize='14', width=1)\n",
    "\n",
    "    ax1.legend(ncol=2, loc='upper left', fontsize=18,shadow=True)\n",
    "    ax2.legend(ncol=2, loc='upper left', fontsize=18,shadow=True)\n",
    "    ax3.legend(ncol=2, loc='upper left', fontsize=18,shadow=True)\n",
    "\n",
    "    plt.savefig(\"graphs/\"+title+\" Predictions.jpg\", format=\"jpg\", dpi=500)  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for st in stations:\n",
    "    plotMAPEFromResults(st)\n",
    "    plot_lstm_preds(st) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50ca854c4c3efc08975ea3cb237e66ea0431a08d0f81600bb6a2a9be70ab2e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
